{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HOSSo94g4fb"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we0mwwMWg8No"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Change directory to root of repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(\"../../PoliGraph-Setup/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db_HXfvGiLUU"
      },
      "source": [
        "## Install dependencies for repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure you create the conda environment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "source": [
        "```sh\n",
        "conda env create -f ./environment.yml\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the cache directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D1enqdCliN7B",
        "outputId": "e516c6c0-733e-49bf-8f5f-e043355c0eed"
      },
      "outputs": [],
      "source": [
        "cache_dir = \"./poligrapher/cache\"\n",
        "\n",
        "if not os.path.exists(cache_dir):\n",
        "    os.makedirs(cache_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import installed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "import yaml\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chX1e5AVqJsJ"
      },
      "source": [
        "## Download the model file from researchers' Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYGUdMQLo-Vg",
        "outputId": "e32523af-f361-4c79-fcb2-7886213469d0"
      },
      "outputs": [],
      "source": [
        "url = \"https://drive.google.com/uc?id=1qHifRx93EfTkg2x1e2W_lgQAgk7HcXhP\"\n",
        "output = \"./poligrapher/cache/poligrapher-extra-data.tar.gz\"\n",
        "\n",
        "if os.path.exists(output):\n",
        "    print(f\"Using cached file: {output}\")\n",
        "else:\n",
        "    print(f\"Downloading file from {url}\")\n",
        "    gdown.download(url, output, quiet=False)\n",
        "    print(f\"File downloaded to: {output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hesotvb5iZDI"
      },
      "source": [
        "## Download spaCy model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3ZYhYUsifcY",
        "outputId": "d946e148-a710-4a21-88d0-e76df9ce3b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading spaCy model...\n",
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "SpaCy model downloaded.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Download spaCy model\n",
        "print(f\"Downloading spaCy model...\")\n",
        "spacy.cli.download(\"en_core_web_md\")\n",
        "print(f\"SpaCy model downloaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbUSm4X-qYgY"
      },
      "source": [
        "## Unzip and move model file to correct folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrgUnmBkp8oS"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "# Extract the tar.gz file\n",
        "with tarfile.open(\"./poligrapher/cache/poligrapher-extra-data.tar.gz\", \"r:gz\") as tar:\n",
        "    tar.extractall(path=\"./poligrapher/extra-data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIx7N8FPq_xT"
      },
      "source": [
        "## Install tool as python package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUEArelrqsqr",
        "outputId": "428c2aa0-1794-4c4a-f8b9-daea6ea47a09"
      },
      "outputs": [],
      "source": [
        "subprocess.run(\n",
        "    [\"conda\", \"run\", \"pip\", \"install\", \"--editable\", \".\"],\n",
        "    check=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beIdrvA1r1V4"
      },
      "source": [
        "## Install browsers so that playwright can scrape web pages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BttUs_LCrxPQ",
        "outputId": "3d5293d8-3904-4d2c-f771-4935d7e58c43",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "source": [
        "```sh\n",
        "playwright install firefox\n",
        "playwright install chromium\n",
        "playwright install msedge\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vynj9x7UrF5z"
      },
      "source": [
        "# Convert privacy policy to knowledge graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create `output/` folder if not present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder_path = \"./output\"\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import poligrapher scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from poligrapher.scripts import (\n",
        "    build_graph,\n",
        "    html_crawler,\n",
        "    init_document,\n",
        "    pdf_parser,\n",
        "    run_annotators,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get policy documents from `policy_list.json` file and generate their knowledge graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpRdmcP3VyDG",
        "outputId": "8b79bd6c-8616-4a82-dcd0-75e532ed101b"
      },
      "outputs": [],
      "source": [
        "from requests import RequestException\n",
        "\n",
        "\n",
        "async def generate_graph_from_html(html_path, output_folder):\n",
        "    \"\"\"\n",
        "    Generate a graph from an HTML file.\n",
        "    \"\"\"\n",
        "    # Run the html crawler\n",
        "    await html_crawler.main(html_path, output_folder)\n",
        "    # Initialize the document\n",
        "    init_document.main(workdirs=[output_folder])\n",
        "    # Run the annotators\n",
        "    run_annotators.main(workdirs=[output_folder])\n",
        "    # Create the graph and generate a .yaml file\n",
        "    build_graph.main(workdirs=[output_folder])\n",
        "    # Create the graph and generate a .graphml file\n",
        "    build_graph.main(pretty=True, workdirs=[output_folder])\n",
        "\n",
        "\n",
        "def needs_graph_generation(output_folder):\n",
        "    \"\"\"\n",
        "    Check if the graph needs to be generated.\n",
        "    \"\"\"\n",
        "    # Check if the output folder contains a .graphml file\n",
        "    graphml_files = glob.glob(os.path.join(output_folder, \"*.graphml\"))\n",
        "    return len(graphml_files) == 0\n",
        "\n",
        "\n",
        "# Open the policy urls file\n",
        "with open(\"./notebooks/policy_list.json\", \"r\") as file:\n",
        "    policy_urls = json.load(file)[\"policy_urls\"]\n",
        "\n",
        "output_folder_prefix = \"./output/\"\n",
        "\n",
        "for policy in policy_urls:\n",
        "    policy_name = policy[\"name\"]\n",
        "    policy_url = policy[\"path\"]\n",
        "    policy_kind = policy[\"kind\"]\n",
        "\n",
        "    # get domain name from url for folder name\n",
        "    output_folder = output_folder_prefix + policy_name.replace(\" \", \"_\")\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    if not needs_graph_generation(output_folder):\n",
        "        print(f\"Graph already exists for {policy_name}, skipping generation.\")\n",
        "        continue\n",
        "    else:\n",
        "        print(f\"Generating graph for {policy_name} from {policy_url}\")\n",
        "\n",
        "    if policy_kind == \"pdf\":\n",
        "        try:\n",
        "            # Run the pdf parser\n",
        "            await pdf_parser.main(policy_url, output_folder)\n",
        "            html_path = os.path.join(output_folder, \"output.html\")\n",
        "            await generate_graph_from_html(html_path, output_folder)\n",
        "            print(f\"Graphs for {policy_url} have been generated using PDF parser\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating graphs for {policy_url}\")\n",
        "            print(e)\n",
        "    elif policy_kind == \"webpage\":\n",
        "        try:\n",
        "            await generate_graph_from_html(policy_url, output_folder)\n",
        "            print(f\"Graphs for {policy_url} have been generated using webpage parser\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating graphs for {policy_url}\")\n",
        "            print(e)\n",
        "    elif policy_kind == \"auto\":\n",
        "        try:\n",
        "            await generate_graph_from_html(policy_url, output_folder)\n",
        "            print(f\"Graphs for {policy_url} have been generated using webpage parser\")\n",
        "        except RequestException as ex:\n",
        "            print(f\"Error generating graphs for {policy_url}\")\n",
        "            print(ex)\n",
        "        except BaseException as e:\n",
        "            try:\n",
        "                # Fallback to the pdf parser method\n",
        "                print(f\"Falling back to PDF parser for {policy_url}\")\n",
        "                await pdf_parser.main(policy_url, output_folder)\n",
        "                html_path = os.path.join(output_folder, \"output.html\")\n",
        "                await generate_graph_from_html(html_path, output_folder)\n",
        "                print(f\"Graphs for {policy_url} have been generated using PDF parser\")\n",
        "            except BaseException as e:\n",
        "                print(f\"Error generating graphs for {policy_url}\")\n",
        "                print(e)\n",
        "    else:\n",
        "        print(f\"Unknown policy kind for {policy_name}: {policy_kind}\")\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# View output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4iTfNJTy9NT"
      },
      "source": [
        "If you just ran the basic command to generate a graph then `graph-original.full.yml` and `graph-original.yml` are the final ouptut. \n",
        "\n",
        "For the pretty graph the output is a `graph-original.graphml` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcrACaVTwrmh",
        "outputId": "55051b6c-a38c-4558-bd4f-86c572b2f54a"
      },
      "outputs": [],
      "source": [
        "subprocess.run([\"ls\", \"-R\", \"./output\"], check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLrTZRdxEA_g"
      },
      "source": [
        "## Visualize the `graph-original.full.yml` file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7PG3FyauN"
      },
      "source": [
        "### Knowledge Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "8gpCknq8ydbX",
        "outputId": "bb811f6a-15f9-49c0-9d42-5c380d1ac645"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"./output\")\n",
        "\n",
        "\n",
        "def needs_graphml_visual(folder):\n",
        "    pattern = os.path.join(folder, \"*\" + \".yml\")\n",
        "    has_graphml = len(glob.glob(pattern)) > 0\n",
        "    if has_graphml:\n",
        "        return not os.path.exists(f\"{folder}/knowledge_graph.png\")\n",
        "    return False\n",
        "\n",
        "\n",
        "# loop through the output folder and get the graph files\n",
        "graph_files = []\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    for dir in dirs:\n",
        "        full_dir_path = os.path.join(root, dir)\n",
        "        if needs_graphml_visual(full_dir_path):\n",
        "            yml_file = os.path.join(full_dir_path, \"graph-original.full.yml\")\n",
        "            if os.path.exists(yml_file) and yml_file not in graph_files:\n",
        "                graph_files.append(yml_file)\n",
        "\n",
        "for graph_file in graph_files:\n",
        "    parent_folder = os.path.dirname(graph_file)\n",
        "    output_png = os.path.join(parent_folder, \"knowledge_graph.png\")\n",
        "    print(f\"Converting {graph_file} to PNG\")\n",
        "\n",
        "    with open(graph_file, \"r\") as file:\n",
        "        data = yaml.safe_load(file)\n",
        "\n",
        "    G = nx.DiGraph()\n",
        "    # nodes\n",
        "    for node in data.get(\"nodes\", []):\n",
        "        G.add_node(node[\"id\"], type=node[\"type\"])\n",
        "    # edges\n",
        "    for link in data.get(\"links\", []):\n",
        "        G.add_edge(link[\"source\"], link[\"target\"], label=link[\"key\"])\n",
        "\n",
        "    plt.figure(figsize=(20, 15), facecolor=\"white\")\n",
        "    pos = nx.spring_layout(G, k=0.5)\n",
        "    nx.draw(\n",
        "        G,\n",
        "        pos,\n",
        "        with_labels=True,\n",
        "        node_size=3000,\n",
        "        node_color=\"lightblue\",\n",
        "        edge_color=\"gray\",\n",
        "    )\n",
        "    edge_labels = nx.get_edge_attributes(G, \"label\")\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "    plt.title(\"Knowledge Graph - \" + parent_folder)\n",
        "    plt.savefig(output_png, facecolor=\"white\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPp5Ljejye9o"
      },
      "source": [
        "### Table of Relations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCcISE-Zyi8K",
        "outputId": "bec2e1c0-ec84-4505-8016-f797c7e0fb4b"
      },
      "outputs": [],
      "source": [
        "def needs_csv_extract(folder):\n",
        "    pattern = os.path.join(folder, \"*\" + \".yml\")\n",
        "    has_graphml = len(glob.glob(pattern)) > 0\n",
        "    if has_graphml:\n",
        "        return not os.path.exists(f\"{folder}/complete_extracted_data.csv\")\n",
        "    return False\n",
        "\n",
        "\n",
        "# load yml file\n",
        "def load_yml(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "                return yaml.safe_load(file)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading YAML: {e}\")\n",
        "    else:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# get relationships from yml file\n",
        "def extract_yml_relationships(yaml_data):\n",
        "    relationships = []\n",
        "    if yml_data and \"links\" in yml_data:\n",
        "        for link in yml_data[\"links\"]:\n",
        "            source = link.get(\"source\", \"Unknown Source\")\n",
        "            target = link.get(\"target\", \"Unknown Target\")\n",
        "            relation = link.get(\"key\", \"Unknown Relationship\")\n",
        "            # combine policy excerpts(references)\n",
        "            text = \" | \".join(link.get(\"text\", []))\n",
        "            purposes = (\n",
        "                \" | \".join(\n",
        "                    [\n",
        "                        f\"{k}: {', '.join(v)}\"\n",
        "                        for k, v in link.get(\"purposes\", {}).items()\n",
        "                    ]\n",
        "                )\n",
        "                if link.get(\"purposes\")\n",
        "                else \"None\"\n",
        "            )\n",
        "            relationships.append((source, relation, target, text, purposes))\n",
        "    return relationships\n",
        "\n",
        "\n",
        "# get file paths\n",
        "yml_path = \"graph-original.full.yml\"\n",
        "\n",
        "# loop through the output folder and get the graph files\n",
        "graph_files = []\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    for dir in dirs:\n",
        "        full_dir_path = os.path.join(root, dir)\n",
        "        if needs_csv_extract(full_dir_path):\n",
        "            yml_file = os.path.join(full_dir_path, yml_path)\n",
        "            if os.path.exists(yml_file) and yml_file not in graph_files:\n",
        "                graph_files.append(yml_file)\n",
        "\n",
        "for graph_file in graph_files:\n",
        "    print(f\"\\nExtracting relationships from '{graph_file}'\")\n",
        "    parent_folder = os.path.dirname(graph_file)\n",
        "    output_csv_path = os.path.join(parent_folder, \"complete_extracted_data.csv\")\n",
        "    # call the funtions\n",
        "    yml_data = load_yml(graph_file)\n",
        "\n",
        "    # get relationships from both files\n",
        "    yml_relationships = extract_yml_relationships(yml_data) if yml_data else []\n",
        "\n",
        "    # combine results to a DF\n",
        "    df_combined = pd.DataFrame(\n",
        "        yml_relationships,\n",
        "        columns=[\"Entity\", \"Relation\", \"Target Entity\", \"Policy Text\", \"Purposes\"],\n",
        "    )\n",
        "\n",
        "    # save the csv\n",
        "    df_combined.to_csv(output_csv_path, index=False)\n",
        "    print(f\"\\nSaved extracted data to '{output_csv_path}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# reset current directory location to where the script started\n",
        "os.chdir(\"../notebooks\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "poligrapher",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
